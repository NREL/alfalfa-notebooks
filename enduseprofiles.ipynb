{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading building models from End Use Profile Datasets and uploading to Alfalfa\n",
    "\n",
    "This script takes in a PUMA or list of PUMAs and downloads individual building models from the End-Use Load Profiles for the U.S. Building Stock datasets. It creates the Alfalfa folder for each building model and associated weather file and uploads them to Alfalfa. \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Before starting this tutorial, spend a few minutes to read through the [README.md](https://data.openei.org/s3_viewer?bucket=oedi-data-lake&prefix=nrel-pds-building-stock%2Fend-use-load-profiles-for-us-building-stock%2F) file, which explains the dataset naming and organizational structure.\n",
    "- An [Amazon AWS account](https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/) is required to follow this tutorial.\n",
    "- Create an AWS access key and secret key pair, as described in the [Programatic access](https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html) section of the AWS documentation.\n",
    "- Put this access key/secret key pair into a text file called `credentials` (notice no file extension) inside your home directory:\n",
    "  - On Windows, this is: `C:\\Users\\myusername\\.aws\\credentials`\n",
    "  - On Mac, this is: `/Users/myusername/.aws/credentials`\n",
    "  - Contents of `credentials` file should look like:\n",
    "\n",
    "    ```\n",
    "    [default]\n",
    "    aws_access_key_id = AKIAIOSFODNN7EXAMPLE\n",
    "    aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n",
    "    ```\n",
    "\n",
    "- Set your default region in a text file called `config` (notice no file extension) inside your home directory:\n",
    "  - On Windows, this is: `C:\\Users\\myusername\\.aws\\config`\n",
    "  - On Mac, this is: `/Users/myusername/.aws/config`\n",
    "  - Contents of `config` file should look like:\n",
    "\n",
    "    ```\n",
    "    [default]\n",
    "    region = us-west-2\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import boto3  # This is not called directly, but must be installed for Pandas to read files from S3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas\n",
    "import datetime\n",
    "import time\n",
    "from alfalfa_client.alfalfa_client import AlfalfaClient\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify PUMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suburban\n",
    "district = 'URBAN EDGE'\n",
    "puma = 'G41001318'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMSTOCK\n",
    "\n",
    "dataset_year_com = '2023'\n",
    "dataset_name_com = 'comstock_amy2018_release_2'\n",
    "dataset_path_com = f's3://oedi-data-lake/nrel-pds-building-stock/end-use-load-profiles-for-us-building-stock/{dataset_year}/{dataset_name}'\n",
    "\n",
    "print(dataset_path_com)\n",
    "\n",
    "## RESSTOCK\n",
    "\n",
    "#dataset_year_res = '2023'\n",
    "#dataset_name_res = 'comstock_amy2018_release_2'\n",
    "#dataset_path_res = f's3://oedi-data-lake/nrel-pds-building-stock/end-use-load-profiles-for-us-building-stock/{dataset_year}/{dataset_name}'\n",
    "\n",
    "#print(dataset_path_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the baseline building characteristics (metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metadata_path = f'{dataset_path}/metadata/baseline.parquet'\n",
    "baseline_meta_df = pd.read_parquet(baseline_metadata_path)\n",
    "baseline_meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all buildings in PUMA\n",
    "\n",
    "Change the filtering logic here to find buildings with whatever characteristics you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = baseline_meta_df.loc[(baseline_meta_df['in.state'] == 'OR') & (baseline_meta_df['in.nhgis_puma_gisjoin'] == 'G41001318')]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the OpenStudio Models \n",
    "(TODO: Expand to all buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    # Get the row of data for this building\n",
    "    bldg_info = teco_df.iloc[i]\n",
    "\n",
    "    # Get the building ID and state ID\n",
    "    bldg_id = bldg_info.name  # bldg_id is the index of the med_off_df dataframe\n",
    "    state_id = bldg_info['in.state']\n",
    "\n",
    "    # Get the upgrade ID\n",
    "    upgrade_id = int(bldg_info['upgrade'])  # Note that we need to convert this to an Integer\n",
    "\n",
    "    # Get the file path for this building's energy model\n",
    "    osm_path = f'{dataset_path}/building_energy_models/by_state/upgrade={upgrade_id}/{bldg_id}-{upgrade_id}.osm.gz'\n",
    "\n",
    "    # Download the model\n",
    "    urllib.request.urlretrieve(\"https://data.openei.org/s3_viewer?bucket=oedi-data-lake&prefix=nrel-pds-building-stock%2Fend-use-load-profiles-for-us-building-stock%2F2023%2Fcomstock_amy2018_release_2%2Fbuilding_energy_models%2Fupgrade%3D18%2F\", f'{bldg_id}.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Alfalfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define alfalfa client object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AlfalfaClient(host='https://alfalfa-staging.nrel.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will create folders for each URBANopt building model that can be uploaded to Alfalfa. The folder contains: \n",
    "\n",
    "    - Model Folder: Contains OpenStudio model (.osm file) for each building\n",
    "    - Measures Folder: Measures to be added while running Alfalfa in the OpenStudio Workflow\n",
    "    - Weather Folder: Contains EPW weather file \n",
    "    - workflow.osw file: OpenStudio workflow file\n",
    "\n",
    "**Define the following variables before running the code**:\n",
    "\n",
    "- `folder` : Folder with building models \n",
    "- `weather`: Define weather file used in URBANopt project\n",
    "- `workflow`: OpenStudio workflow file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder name\n",
    "folder = Path('')\n",
    "\n",
    "folder_name = folder.name\n",
    "folder_path = Path(f\"./{folder_name}_alfalfa\")\n",
    "if folder_path.exists():\n",
    "    shutil.rmtree(folder_path)\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Folders saved at {folder_path}\")\n",
    "\n",
    "# Add .epw filename\n",
    "weather = \"USA_CO_Denver.Intl.AP.725650_TMY3.epw\"\n",
    "\n",
    "# Add .osw filename\n",
    "workflow = \"workflow.osw\"\n",
    "\n",
    "for file in folder.iterdir():\n",
    "\n",
    "    if file.is_dir() and (file / 'in.osm').exists():\n",
    "        model_filepath = folder_path / file.name\n",
    "        model_filepath.mkdir(parents=True, exist_ok=True)\n",
    "        (model_filepath / 'models').mkdir(parents=True, exist_ok=True)\n",
    "        (model_filepath / 'measures').mkdir(parents=True, exist_ok=True)\n",
    "        (model_filepath / 'weather').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        shutil.copy((file / 'in.osm'), (model_filepath / 'models' / f'{file.name}.osm'))\n",
    "        shutil.copy((folder / '../../weather' / weather), (model_filepath / 'weather'))\n",
    "\n",
    "        osw = {\"seed_file\": f\"{file.name}.osm\",\n",
    "           \"weather_file\": f\"{weather}\",\n",
    "           \"measure_paths\": [\"./measures\"],\n",
    "           \"run_directory\": \"./run/\",\n",
    "           \"file_paths\": [\n",
    "               \"./weather/\",\n",
    "               \"./models/\"\n",
    "           ],\n",
    "            \"steps\" : [\n",
    "                {\n",
    "                    \"measure_dir_name\" : \"alfalfa_vars\",\n",
    "                    \"name\" : \"Alfalfa Variables\",\n",
    "                    \"description\" : \"Add custom variables for Alfalfa\",\n",
    "                    \"modeler_description\" : \"Add EMS global variables required by Alfalfa\",\n",
    "                    \"arguments\" : {\n",
    "                        \"model\" : f\"{file.name}.osm\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "          }\n",
    "\n",
    "        f = open((model_filepath / workflow), \"w+\")\n",
    "        f.write(json.dumps(osw, indent=4))\n",
    "        f.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload models to Alfalfa\n",
    "\n",
    "Submit models to Alfalfa server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(folder_path.iterdir())\n",
    "print(f\"uploading {files}\")\n",
    "model_ids = ac.submit(files)\n",
    "print(model_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Alfalfa simulation parameters\n",
    "\n",
    "- start_dt : This is the start date and time for the simulation in the following format (YYYY, M, D, H, M, S)\n",
    "- end_dt : This is the end date and time for the simulation in the following format (YYYY, M, D, H, M, S)\n",
    "- params : This defines the simulation parameters for the simulation including the start/end date and time and whether the model advances via API calls or a specified timescale\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using historian, you will need to search for this time period in Grafana dashboard to view results.\n",
    "start_dt = datetime.datetime(2023, 5, 10, 12, 2, 0)\n",
    "end_dt = datetime.datetime(2023, 5, 10, 12, 3, 0)\n",
    "\n",
    "# For external_clock == true, API calls are used to advance the model.\n",
    "# If external_clock == false, Alfalfa will handle advancing the model according to a specified timescale (timescale 1 => realtime)\n",
    "params = {\n",
    "    \"external_clock\": True,\n",
    "    \"start_datetime\": start_dt,\n",
    "    \"end_datetime\": end_dt\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start simulations \n",
    "\n",
    "Start simulations as per the parameters defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Simulations\n",
    "print(f\"Starting site: {model_ids}\")\n",
    "ac.start(model_ids, **params)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the model ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model ID\n",
    "model_id = '37bf8900-8edd-11ee-80a8-f546b406f534'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the model's input points\n",
    "Get a list of all of the model's input points (EP Actuators)\n",
    "- model_id - the id of the site returned by the `ac.submit` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model_id} inputs:\")\n",
    "pprint(ac.get_inputs(model_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model input point\n",
    "\n",
    "To set an input value use the `ac.set_inputs(model_id, inputs)` function.\n",
    "\n",
    "- `inputs_dict` - a dictionary of input names and the desired values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {'Zone_PVAV_with_PFP_Boxes_and_Reheat_1_Outside_Air_Damper_CMD': 10}\n",
    "ac.set_inputs(model_id, input_dict)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advance the model\n",
    "12/10/2021: timestep is hardcoded to 1 minute w/in Alfalfa worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 5\n",
    "for _ in range(timesteps):\n",
    "    ac.advance([model_id])\n",
    "    print(f\"Model advanced to time: {ac.get_sim_time(model_id)}\")\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model's outputs\n",
    "Query the outputs (EP Sensors) of the models as well as their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model_id} outputs:\")\n",
    "\n",
    "# Print Simulation Time\n",
    "pprint(ac.get_sim_time(model_id))\n",
    "\n",
    "# Print output values\n",
    "pprint(ac.get_outputs(model_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.stop(model_id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a23527e6104694a83f14c6c8bca9b94c3b423d2b6ecf25ebd988d67879adb7f8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
