{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading building models from End Use Profile Datasets and uploading to Alfalfa\n",
    "\n",
    "This script takes in a PUMA or list of PUMAs and downloads individual building models from the End-Use Load Profiles for the U.S. Building Stock datasets. It creates the Alfalfa folder for each building model and associated weather file and uploads them to Alfalfa. \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Before starting this tutorial, spend a few minutes to read through the [README.md](https://data.openei.org/s3_viewer?bucket=oedi-data-lake&prefix=nrel-pds-building-stock%2Fend-use-load-profiles-for-us-building-stock%2F) file, which explains the dataset naming and organizational structure.\n",
    "- An [Amazon AWS account](https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/) is required to follow this tutorial.\n",
    "- Create an AWS access key and secret key pair, as described in the [Programatic access](https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html) section of the AWS documentation.\n",
    "- Put this access key/secret key pair into a text file called `credentials` (notice no file extension) inside your home directory:\n",
    "  - On Windows, this is: `C:\\Users\\myusername\\.aws\\credentials`\n",
    "  - On Mac, this is: `/Users/myusername/.aws/credentials`\n",
    "  - Contents of `credentials` file should look like:\n",
    "\n",
    "    ```\n",
    "    [default]\n",
    "    aws_access_key_id = AKIAIOSFODNN7EXAMPLE\n",
    "    aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n",
    "    ```\n",
    "\n",
    "- Set your default region in a text file called `config` (notice no file extension) inside your home directory:\n",
    "  - On Windows, this is: `C:\\Users\\myusername\\.aws\\config`\n",
    "  - On Mac, this is: `/Users/myusername/.aws/config`\n",
    "  - Contents of `config` file should look like:\n",
    "\n",
    "    ```\n",
    "    [default]\n",
    "    region = us-west-2\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import boto3  # This is not called directly, but must be installed for Pandas to read files from S3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas\n",
    "import datetime\n",
    "import time\n",
    "from alfalfa_client.alfalfa_client import AlfalfaClient\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify PUMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suburban\n",
    "district = 'URBAN EDGE'\n",
    "puma = 'G41001318'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMSTOCK\n",
    "\n",
    "dataset_year_com = '2023'\n",
    "dataset_name_com = 'comstock_amy2018_release_2'\n",
    "dataset_path_com = f's3://oedi-data-lake/nrel-pds-building-stock/end-use-load-profiles-for-us-building-stock/{dataset_year}/{dataset_name}'\n",
    "\n",
    "print(dataset_path_com)\n",
    "\n",
    "## RESSTOCK\n",
    "\n",
    "#dataset_year_res = '2023'\n",
    "#dataset_name_res = 'comstock_amy2018_release_2'\n",
    "#dataset_path_res = f's3://oedi-data-lake/nrel-pds-building-stock/end-use-load-profiles-for-us-building-stock/{dataset_year}/{dataset_name}'\n",
    "\n",
    "#print(dataset_path_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the baseline building characteristics (metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metadata_path = f'{dataset_path}/metadata/baseline.parquet'\n",
    "baseline_meta_df = pd.read_parquet(baseline_metadata_path)\n",
    "baseline_meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all buildings in PUMA\n",
    "\n",
    "Change the filtering logic here to find buildings with whatever characteristics you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = baseline_meta_df.loc[(baseline_meta_df['in.state'] == 'OR') & (baseline_meta_df['in.nhgis_puma_gisjoin'] == 'G41001318')]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the OpenStudio Models \n",
    "(TODO: Expand to all buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    # Get the row of data for this building\n",
    "    bldg_info = teco_df.iloc[i]\n",
    "\n",
    "    # Get the building ID and state ID\n",
    "    bldg_id = bldg_info.name  # bldg_id is the index of the med_off_df dataframe\n",
    "    state_id = bldg_info['in.state']\n",
    "\n",
    "    # Get the upgrade ID\n",
    "    upgrade_id = int(bldg_info['upgrade'])  # Note that we need to convert this to an Integer\n",
    "\n",
    "    # Get the file path for this building's energy model\n",
    "    osm_path = f'{dataset_path}/building_energy_models/by_state/upgrade={upgrade_id}/{bldg_id}-{upgrade_id}.osm.gz'\n",
    "\n",
    "    # Download the model\n",
    "    urllib.request.urlretrieve(\"https://data.openei.org/s3_viewer?bucket=oedi-data-lake&prefix=nrel-pds-building-stock%2Fend-use-load-profiles-for-us-building-stock%2F2023%2Fcomstock_amy2018_release_2%2Fbuilding_energy_models%2Fupgrade%3D18%2F\", f'{bldg_id}.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Alfalfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define alfalfa client object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AlfalfaClient(host='https://alfalfa-staging.nrel.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will create folders for each URBANopt building model that can be uploaded to Alfalfa. The folder contains: \n",
    "\n",
    "    - Model Folder: Contains OpenStudio model (.osm file) for each building\n",
    "    - Measures Folder: Measures to be added while running Alfalfa in the OpenStudio Workflow\n",
    "    - Weather Folder: Contains EPW weather file \n",
    "    - workflow.osw file: OpenStudio workflow file\n",
    "\n",
    "**Define the following variables before running the code**:\n",
    "\n",
    "- `folder` : Folder with building models \n",
    "- `weather`: Define weather file used in URBANopt project\n",
    "- `workflow`: OpenStudio workflow file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder name\n",
    "folder = Path('')\n",
    "\n",
    "folder_name = folder.name\n",
    "folder_path = Path(f\"./{folder_name}_alfalfa\")\n",
    "if folder_path.exists():\n",
    "    shutil.rmtree(folder_path)\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Folders saved at {folder_path}\")\n",
    "\n",
    "# Add .epw filename\n",
    "weather = \"USA_CO_Denver.Intl.AP.725650_TMY3.epw\"\n",
    "\n",
    "# Add .osw filename\n",
    "workflow = \"workflow.osw\"\n",
    "\n",
    "for file in folder.iterdir():\n",
    "\n",
    "    if file.is_dir() and (file / 'in.osm').exists():\n",
    "        model_filepath = folder_path / file.name\n",
    "        model_filepath.mkdir(parents=True, exist_ok=True)\n",
    "        (model_filepath / 'models').mkdir(parents=True, exist_ok=True)\n",
    "        (model_filepath / 'measures').mkdir(parents=True, exist_ok=True)\n",
    "        (model_filepath / 'weather').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        shutil.copy((file / 'in.osm'), (model_filepath / 'models' / f'{file.name}.osm'))\n",
    "        shutil.copy((folder / '../../weather' / weather), (model_filepath / 'weather'))\n",
    "\n",
    "        osw = {\"seed_file\": f\"{file.name}.osm\",\n",
    "           \"weather_file\": f\"{weather}\",\n",
    "           \"measure_paths\": [\"./measures\"],\n",
    "           \"run_directory\": \"./run/\",\n",
    "           \"file_paths\": [\n",
    "               \"./weather/\",\n",
    "               \"./models/\"\n",
    "           ],\n",
    "            \"steps\" : [\n",
    "                {\n",
    "                    \"measure_dir_name\" : \"alfalfa_vars\",\n",
    "                    \"name\" : \"Alfalfa Variables\",\n",
    "                    \"description\" : \"Add custom variables for Alfalfa\",\n",
    "                    \"modeler_description\" : \"Add EMS global variables required by Alfalfa\",\n",
    "                    \"arguments\" : {\n",
    "                        \"model\" : f\"{file.name}.osm\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "          }\n",
    "\n",
    "        f = open((model_filepath / workflow), \"w+\")\n",
    "        f.write(json.dumps(osw, indent=4))\n",
    "        f.close()\n",
    "\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a23527e6104694a83f14c6c8bca9b94c3b423d2b6ecf25ebd988d67879adb7f8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
