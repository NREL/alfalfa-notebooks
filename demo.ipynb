{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca9cde5",
   "metadata": {},
   "source": [
    "# Example running and interacting with multiple buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf348d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from alfalfa_client.alfalfa_client import AlfalfaClient\n",
    "from alfalfa_openadr.oadr_client import OADRClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93f2d3",
   "metadata": {},
   "source": [
    "url should be for running [Alfalfa deployment](https://github.com/NREL/alfalfa/wiki/Deployment) with **at least two workers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6f2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new client.\n",
    "# Update url for remote deployments\n",
    "ac = AlfalfaClient(url='http://localhost')\n",
    "dr_client = OADRClient(url='http://localhost:5000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5bbfc",
   "metadata": {},
   "source": [
    "The model_paths below assume the (acess restricted) CCTwin repo is cloned in the same root as this Alfalfa-notebooks repo with branch `apr22demo` checked out.  If not, you will need to update the model_paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a981f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../CCTwin-scripts/bldg_models/sfhome/sfhome.zip', '../CCTwin-scripts/bldg_models/sfhome/sfhome.zip']\n"
     ]
    }
   ],
   "source": [
    "# Local paths to models for upload\n",
    "model_paths = []\n",
    "\n",
    "# all_models = range(0,317)\n",
    "# for full experiment use range(0,317)\n",
    "for i in range(0,2):\n",
    "    model_paths.append(f'../CCTwin-scripts/bldg_models/sfhome/sfhome.zip')\n",
    "\n",
    "print(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83eed335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../CCTwin-scripts/bldg_models/sfhome/sfhome.zip\n",
      "Desired status: READY\t\tCurrent status: PREPROCESSING\n",
      "../CCTwin-scripts/bldg_models/sfhome/sfhome.zip\n",
      "Desired status: READY\t\tCurrent status: PREPROCESSING\n"
     ]
    }
   ],
   "source": [
    "# Upload to Alfalfa \n",
    "model_ids = []\n",
    "for p in model_paths:\n",
    "    print(p)\n",
    "    # TODO add error handling\n",
    "    # TODO send uploads asyncronously. \n",
    "    # Currently we have sufficient workers to upload in parallel, but this Python loop is forcing them to run in serial.\n",
    "    model_ids.append(ac.submit(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3e5857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d125451e-e8dd-11ec-b1ba-acde48001122', 'd3922844-e8dd-11ec-b1ba-acde48001122']\n"
     ]
    }
   ],
   "source": [
    "print(model_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db94646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the run parameters.  \n",
    "# If you are using historian, you will need to search for this time period in Grafana dashboard to view results.\n",
    "start_dt = datetime.datetime(2017, 9, 26, 0, 0, 0)\n",
    "end_dt = datetime.datetime(2017, 9, 27, 0, 0, 0)\n",
    "\n",
    "# For external_clock == true, API calls are used to advance the model.  \n",
    "# If external_clock == false, Alfalfa will handle advancing the model according to a specified timescale (timescale 1 => realtime)\n",
    "params = {\n",
    "    \"external_clock\": \"true\",\n",
    "    \"start_datetime\": start_dt,\n",
    "    \"end_datetime\": end_dt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020b9269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d125451e-e8dd-11ec-b1ba-acde48001122\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: RUNNING\n",
      "d3922844-e8dd-11ec-b1ba-acde48001122\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n",
      "Desired status: RUNNING\t\tCurrent status: STARTED\n"
     ]
    }
   ],
   "source": [
    "# Start simulations.  since we're using external clock, will take through warmup and wait for an advance\n",
    "for i in model_ids:\n",
    "    print(i)\n",
    "    ac.start(i, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c317e54",
   "metadata": {},
   "source": [
    "### Note that this currently advances models \"as fast as possible\" and isn't attempting to track with real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d486b7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-26 00:00:00, community aggregate: 180740.17593316216\n",
      "2017-09-26 00:01:00, community aggregate: 133061.25066372845\n",
      "2017-09-26 00:02:00, community aggregate: 132497.6383576323\n",
      "2017-09-26 00:03:00, community aggregate: 132070.68354430117\n",
      "2017-09-26 00:04:00, community aggregate: 131675.87134059786\n",
      "2017-09-26 00:05:00, community aggregate: 131296.46702833145\n",
      "2017-09-26 00:06:00, community aggregate: 130925.16548272932\n",
      "2017-09-26 00:07:00, community aggregate: 130557.5221368968\n",
      "2017-09-26 00:08:00, community aggregate: 130194.66224006668\n",
      "2017-09-26 00:09:00, community aggregate: 129832.20912225304\n",
      "2017-09-26 00:10:00, community aggregate: 129474.4253060012\n",
      "2017-09-26 00:11:00, community aggregate: 129118.5947361834\n",
      "2017-09-26 00:12:00, community aggregate: 128765.21904689237\n",
      "2017-09-26 00:13:00, community aggregate: 128413.50897679394\n",
      "2017-09-26 00:14:00, community aggregate: 128064.54253924207\n",
      "2017-09-26 00:15:00, community aggregate: 127717.29648353787\n",
      "2017-09-26 00:16:00, community aggregate: 127371.88470846917\n",
      "2017-09-26 00:17:00, community aggregate: 127027.7304965121\n",
      "2017-09-26 00:18:00, community aggregate: 126685.88821387549\n",
      "2017-09-26 00:19:00, community aggregate: 126344.37494472237\n"
     ]
    }
   ],
   "source": [
    "#run for 1 day  \n",
    "# timesteps = 1440\n",
    "\n",
    "# limited timesteps during testing\n",
    "timesteps = 20\n",
    "\n",
    "# main loop advances simulation and handles model i/o for each timestep\n",
    "\n",
    "for i in range(timesteps):\n",
    "    aggregate_load_for_timestep = 0\n",
    "    # Load current timestamp from one sim.  \n",
    "    # note you could avoid an api call by adding 60 to start time each iteration\n",
    "    t = ac.get_sim_time(model_ids[0])\n",
    "\n",
    "    # Load current values from each model\n",
    "    for mid in model_ids:\n",
    "        outputs = ac.outputs(mid)\n",
    "        #print(outputs)\n",
    "\n",
    "        # Note the key here is configured in the uploaded model\n",
    "        # TODO error handling if not present\n",
    "        main = outputs['Electric Meter']\n",
    "        aggregate_load_for_timestep+= main\n",
    "\n",
    "    signals = dr_client.signals()\n",
    "    signal_write_value = \"0\"\n",
    "    for signal in signals:\n",
    "        if signal['signalName'] == \"simple\" and signal['signalType'] == \"level\":\n",
    "            signal_write_value = signal['payload']\n",
    "\n",
    "    for id in model_ids:\n",
    "        inputs = ac.inputs(id)\n",
    "        if signal_write_value:\n",
    "            inputs['AlfalfaTest'] = signal_write_value\n",
    "            ac.setInputs(id, inputs)\n",
    "        \n",
    "\n",
    "    # do somethinig with the aggregate demand across buildings for this timestep\n",
    "    # note that outside this notebook we also are persisting all outputs by building to InfluxDB each timestep\n",
    "    print(f\"{t}, community aggregate: {aggregate_load_for_timestep}\")\n",
    "\n",
    "    # Advance the models.  \n",
    "    # as currently implemented, there is some serial/blocking execution here at the web layer \n",
    "    # which may add up delays when run for 100s buildings\n",
    "    ac.advance(model_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1d1839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired status: COMPLETE\t\tCurrent status: STOPPING\n",
      "Desired status: COMPLETE\t\tCurrent status: COMPLETE\n",
      "Desired status: COMPLETE\t\tCurrent status: STOPPING\n",
      "Desired status: COMPLETE\t\tCurrent status: COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Stop the models\n",
    "for id in model_ids:\n",
    "    ac.stop(id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4e15f636d375cde676b1a1c889053ee99561357f6fd296cf9e4c457fad780d8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
