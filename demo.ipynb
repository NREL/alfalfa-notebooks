{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca9cde5",
   "metadata": {},
   "source": [
    "# Example running and interacting with multiple buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf348d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from alfalfa_client.alfalfa_client import AlfalfaClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93f2d3",
   "metadata": {},
   "source": [
    "url should be for running [Alfalfa deployment](https://github.com/NREL/alfalfa/wiki/Deployment) with **at least two workers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new client.\n",
    "# Update url for remote deployments\n",
    "ac = AlfalfaClient(url='http://localhost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5bbfc",
   "metadata": {},
   "source": [
    "The model_paths below assume the (acess restricted) CCTwin repo is cloned in the same root as this Alfalfa-notebooks repo.  If not, you will need to update the model_paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a981f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local paths to models for upload\n",
    "model_paths = []\n",
    "\n",
    "# all_models = range(0,317)\n",
    "# for full experiment use range(0,317)\n",
    "for i in range(0,2):\n",
    "    model_paths.append(f'../CCTwin-scripts/bldg_models/apr22demo/zips/{i:03}.zip')\n",
    "\n",
    "print(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eed335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to Alfalfa \n",
    "model_ids = {}\n",
    "for p in model_paths:\n",
    "    print(p)\n",
    "    # TODO add error handling\n",
    "    # TODO send uploads asyncronously. \n",
    "    # Currently we have sufficient workers to upload in parallel, but this Python loop is forcing them to run in serial.\n",
    "    model_ids[p] = ac.submit(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db94646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the run parameters.  \n",
    "# If you are using historian, you will need to search for this time period in Grafana dashboard to view results.\n",
    "start_dt = datetime.datetime(2017, 9, 26, 0, 0, 0)\n",
    "end_dt = datetime.datetime(2017, 9, 27, 0, 0, 0)\n",
    "\n",
    "# For external_clock == true, API calls are used to advance the model.  \n",
    "# If external_clock == false, Alfalfa will handle advancing the model according to a specified timescale (timescale 1 => realtime)\n",
    "params = {\n",
    "    \"external_clock\": \"true\",\n",
    "    \"start_datetime\": start_dt,\n",
    "    \"end_datetime\": end_dt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start simulations.  since we're using external clock, will take through warmup and wait for an advance\n",
    "for i in model_ids.values():\n",
    "    print(i)\n",
    "    ac.start(i, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for 1 day  \n",
    "# timesteps = 1440\n",
    "\n",
    "# limited timesteps during testing\n",
    "timesteps = 2\n",
    "\n",
    "# main loop advances simulation and handles model i/o for each timestep\n",
    "\n",
    "for i in range(timesteps):\n",
    "    aggregate_load_for_timestep = 0\n",
    "    # Load current timestamp from one sim.  \n",
    "    # note you could avoid an api call by adding 60 to start time each iteration\n",
    "    t = ac.get_sim_time(list(model_ids.values())[0])\n",
    "\n",
    "    # Load current values from each model\n",
    "    for mid in model_ids.values():\n",
    "        outputs = ac.outputs(mid)\n",
    "        #print(outputs)\n",
    "\n",
    "        # Note the key here is configured in the uploaded model\n",
    "        # TODO error handling if not present\n",
    "        main = outputs['Electric Meter']\n",
    "        agg+= main\n",
    "\n",
    "    # do somethinig with the aggregate demand across buildings for this timestep\n",
    "    # note that outside this notebook we also are persisting all outputs by building to InfluxDB each timestep\n",
    "    print(f\"{t}, community aggregate: {agg}\")\n",
    "\n",
    "    # Advance the models.  \n",
    "    # as currently implemented, there is some serial/blocking execution here at the web layer \n",
    "    # which may add up delays when run for 100s buildings\n",
    "    ac.advance(model_ids.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the models\n",
    "for id in model_ids.values():\n",
    "    ac.stop(id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4e15f636d375cde676b1a1c889053ee99561357f6fd296cf9e4c457fad780d8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
